{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48b00fe",
   "metadata": {},
   "source": [
    "## INSTRUCTIONS \n",
    "\n",
    "Every learner should submit his/her own homework solutions. However, you are allowed to discuss the homework with each other– but everyone must submit his/her own solution; you may not copy someone else’s solution. \n",
    "\n",
    "The homework consists of two parts:\n",
    "1.\tData from our life\n",
    "2.\tClassification\n",
    "\n",
    "Follow the prompts in the attached jupyter notebook. We are using the same data as for the previous homeworks. Use the version you created called df2 where you already cleaned, dropped some of the variables but did not create dummy variables. Instead of creating dummy variables, you have to recode this column as suggested bellow.\n",
    "Add markdown cells to your analysis to include your solutions, comments, answers. Add as many cells as you need, for easy readability comment when possible. \n",
    "\n",
    "**Note:** This homework has a bonus question, so the highest mark that can be earned is a 105.\n",
    "Submission: Send in both a ipynb and a pdf file of your work.\n",
    "Good luck!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb31fa",
   "metadata": {},
   "source": [
    "# 1. Data from our lives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc0963",
   "metadata": {},
   "source": [
    "### Describe a situation or problem from your job, everyday life, current events, etc., for which a classification would be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34f3e2",
   "metadata": {},
   "source": [
    "## Your answer\n",
    "\n",
    "Situation: Movie Genre Classification\n",
    "In the vast world of movies, there's an incredible variety of genres—action, romance, comedy, thriller, and many more. Imagine a scenario where a movie enthusiast wants to build a system that can automatically categorize movies into their respective genres based solely on their plot summaries or descriptions.\n",
    "Imagine a movie enthusiast developing a system to automatically categorize movies into genres using plot summaries. They gather a diverse dataset containing plot summaries linked to respective genres. Extracting key features like word frequency and sentiment, the system cleans and transforms text into machine-readable data. Using smart classification techniques, it learns patterns connecting features to genres through rigorous training and evaluation. Once validated, the system predicts genres for new movie plots, providing personalized recommendations, enhancing the movie-watching experience, and aiding users in discovering films aligned with their preferences on streaming platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7df56",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4e2d8",
   "metadata": {},
   "source": [
    "In our class we covered multiple classification methods. In this part of the home work you can compare them \n",
    "\n",
    "**Use the dataset 'auto_imports1.csv' from our previous homeworks. More specifically, use the version you created called df2 where you already cleaned, dropped some of the variables but DID NOT CREATE dummy variables. Follow the prompts to complete the homework.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356dab7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de9950c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82eaddd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>body</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>heights</th>\n",
       "      <th>curb_weight</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>comprassion</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gas</td>\n",
       "      <td>convertible</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gas</td>\n",
       "      <td>convertible</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gas</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>six</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gas</td>\n",
       "      <td>sedan</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gas</td>\n",
       "      <td>sedan</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fuel_type         body  wheel_base  length  width  heights  curb_weight  \\\n",
       "0       gas  convertible        88.6   168.8   64.1     48.8         2548   \n",
       "1       gas  convertible        88.6   168.8   64.1     48.8         2548   \n",
       "2       gas    hatchback        94.5   171.2   65.5     52.4         2823   \n",
       "3       gas        sedan        99.8   176.6   66.2     54.3         2337   \n",
       "4       gas        sedan        99.4   176.6   66.4     54.3         2824   \n",
       "\n",
       "  engine_type cylinders  engine_size  bore stroke  comprassion horse_power  \\\n",
       "0        dohc      four          130  3.47   2.68          9.0         111   \n",
       "1        dohc      four          130  3.47   2.68          9.0         111   \n",
       "2        ohcv       six          152  2.68   3.47          9.0         154   \n",
       "3         ohc      four          109  3.19    3.4         10.0         102   \n",
       "4         ohc      five          136  3.19    3.4          8.0         115   \n",
       "\n",
       "  peak_rpm  city_mpg  highway_mpg  price  \n",
       "0     5000        21           27  13495  \n",
       "1     5000        21           27  16500  \n",
       "2     5000        19           26  16500  \n",
       "3     5500        24           30  13950  \n",
       "4     5500        18           22  17450  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in data\n",
    "df =pd.read_csv('auto_imports1.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37b2aea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fuel_type       object\n",
       "body            object\n",
       "wheel_base     float64\n",
       "length         float64\n",
       "width          float64\n",
       "heights        float64\n",
       "curb_weight      int64\n",
       "engine_type     object\n",
       "cylinders       object\n",
       "engine_size      int64\n",
       "bore            object\n",
       "stroke          object\n",
       "comprassion    float64\n",
       "horse_power     object\n",
       "peak_rpm        object\n",
       "city_mpg         int64\n",
       "highway_mpg      int64\n",
       "price            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##your code here\n",
    "# To Check the data types in the DataFrame\n",
    "car_data_types = df.dtypes\n",
    "\n",
    "car_data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59de9712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no remaining '?' values in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "## Your code here\n",
    "\n",
    "# To Replace '?' with None\n",
    "df = df.replace('?', None)\n",
    "\n",
    "# To Convert bore, stroke, horse_power, peak_rpm to float64\n",
    "object_columns_to_float = [\"bore\", \"stroke\", \"horse_power\", \"peak_rpm\"]\n",
    "df[object_columns_to_float] = df[object_columns_to_float].astype(float)\n",
    "\n",
    "# To Check if any remaining '?' values\n",
    "if '?' in df.values:\n",
    "    print(\"There are remaining '?' values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no remaining '?' values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02bcec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201 entries, 0 to 200\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   fuel_type    201 non-null    object \n",
      " 1   body         201 non-null    object \n",
      " 2   wheel_base   201 non-null    float64\n",
      " 3   length       201 non-null    float64\n",
      " 4   width        201 non-null    float64\n",
      " 5   heights      201 non-null    float64\n",
      " 6   curb_weight  201 non-null    int64  \n",
      " 7   engine_type  201 non-null    object \n",
      " 8   cylinders    201 non-null    object \n",
      " 9   engine_size  201 non-null    int64  \n",
      " 10  bore         197 non-null    float64\n",
      " 11  stroke       197 non-null    float64\n",
      " 12  comprassion  201 non-null    float64\n",
      " 13  horse_power  199 non-null    float64\n",
      " 14  peak_rpm     199 non-null    float64\n",
      " 15  city_mpg     201 non-null    int64  \n",
      " 16  highway_mpg  201 non-null    int64  \n",
      " 17  price        201 non-null    int64  \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 28.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c2f0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n",
    "\n",
    "# Dropping body,engine_type, cylinders columns from the dataset and renaming as df2\n",
    "df.drop(columns=[\"body\", \"engine_type\", \"cylinders\"], inplace=True)\n",
    "\n",
    "# renaming df as df2 \n",
    "df2 = df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "814afa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>heights</th>\n",
       "      <th>curb_weight</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>comprassion</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gas</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gas</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gas</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gas</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gas</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fuel_type  wheel_base  length  width  heights  curb_weight  engine_size  \\\n",
       "0       gas        88.6   168.8   64.1     48.8         2548          130   \n",
       "1       gas        88.6   168.8   64.1     48.8         2548          130   \n",
       "2       gas        94.5   171.2   65.5     52.4         2823          152   \n",
       "3       gas        99.8   176.6   66.2     54.3         2337          109   \n",
       "4       gas        99.4   176.6   66.4     54.3         2824          136   \n",
       "\n",
       "   bore  stroke  comprassion  horse_power  peak_rpm  city_mpg  highway_mpg  \\\n",
       "0  3.47    2.68          9.0        111.0    5000.0        21           27   \n",
       "1  3.47    2.68          9.0        111.0    5000.0        21           27   \n",
       "2  2.68    3.47          9.0        154.0    5000.0        19           26   \n",
       "3  3.19    3.40         10.0        102.0    5500.0        24           30   \n",
       "4  3.19    3.40          8.0        115.0    5500.0        18           22   \n",
       "\n",
       "   price  \n",
       "0  13495  \n",
       "1  16500  \n",
       "2  16500  \n",
       "3  13950  \n",
       "4  17450  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81907e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "\n",
    "## Droping rows with NaN values in the Dataset\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0ce0b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fuel_type      0\n",
       "wheel_base     0\n",
       "length         0\n",
       "width          0\n",
       "heights        0\n",
       "curb_weight    0\n",
       "engine_size    0\n",
       "bore           0\n",
       "stroke         0\n",
       "comprassion    0\n",
       "horse_power    0\n",
       "peak_rpm       0\n",
       "city_mpg       0\n",
       "highway_mpg    0\n",
       "price          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91a6106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Your code goes here\n",
    "\n",
    "\n",
    "# # Creating dummy variables for fuel_type\n",
    "# dummy_fuel_type = pd.get_dummies(df2['fuel_type'], prefix='fuel_type')\n",
    "\n",
    "# # Droping the first level of dummy variable\n",
    "# dummy_fuel_type = dummy_fuel_type.iloc[:, 1:]\n",
    "\n",
    "# # Replacing the original 'fuel_type' column with the dummy variables\n",
    "# df2 = pd.concat([df2, dummy_fuel_type], axis=1)\n",
    "\n",
    "# # Droping the original 'fuel_type' column\n",
    "# df2 = df2.drop(columns='fuel_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "090a4d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 195 entries, 0 to 200\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   fuel_type    195 non-null    object \n",
      " 1   wheel_base   195 non-null    float64\n",
      " 2   length       195 non-null    float64\n",
      " 3   width        195 non-null    float64\n",
      " 4   heights      195 non-null    float64\n",
      " 5   curb_weight  195 non-null    int64  \n",
      " 6   engine_size  195 non-null    int64  \n",
      " 7   bore         195 non-null    float64\n",
      " 8   stroke       195 non-null    float64\n",
      " 9   comprassion  195 non-null    float64\n",
      " 10  horse_power  195 non-null    float64\n",
      " 11  peak_rpm     195 non-null    float64\n",
      " 12  city_mpg     195 non-null    int64  \n",
      " 13  highway_mpg  195 non-null    int64  \n",
      " 14  price        195 non-null    int64  \n",
      "dtypes: float64(9), int64(5), object(1)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "561041cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>heights</th>\n",
       "      <th>curb_weight</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>comprassion</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gas</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gas</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gas</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gas</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gas</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fuel_type  wheel_base  length  width  heights  curb_weight  engine_size  \\\n",
       "0       gas        88.6   168.8   64.1     48.8         2548          130   \n",
       "1       gas        88.6   168.8   64.1     48.8         2548          130   \n",
       "2       gas        94.5   171.2   65.5     52.4         2823          152   \n",
       "3       gas        99.8   176.6   66.2     54.3         2337          109   \n",
       "4       gas        99.4   176.6   66.4     54.3         2824          136   \n",
       "\n",
       "   bore  stroke  comprassion  horse_power  peak_rpm  city_mpg  highway_mpg  \\\n",
       "0  3.47    2.68          9.0        111.0    5000.0        21           27   \n",
       "1  3.47    2.68          9.0        111.0    5000.0        21           27   \n",
       "2  2.68    3.47          9.0        154.0    5000.0        19           26   \n",
       "3  3.19    3.40         10.0        102.0    5500.0        24           30   \n",
       "4  3.19    3.40          8.0        115.0    5500.0        18           22   \n",
       "\n",
       "   price  \n",
       "0  13495  \n",
       "1  16500  \n",
       "2  16500  \n",
       "3  13950  \n",
       "4  17450  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98f9a9",
   "metadata": {},
   "source": [
    "## 2.1 **Replace ['gas', 'diesel'] string values to [0, 1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "127b23b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>heights</th>\n",
       "      <th>curb_weight</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>comprassion</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fuel_type  wheel_base  length  width  heights  curb_weight  engine_size  \\\n",
       "0         0        88.6   168.8   64.1     48.8         2548          130   \n",
       "1         0        88.6   168.8   64.1     48.8         2548          130   \n",
       "2         0        94.5   171.2   65.5     52.4         2823          152   \n",
       "3         0        99.8   176.6   66.2     54.3         2337          109   \n",
       "4         0        99.4   176.6   66.4     54.3         2824          136   \n",
       "\n",
       "   bore  stroke  comprassion  horse_power  peak_rpm  city_mpg  highway_mpg  \\\n",
       "0  3.47    2.68          9.0        111.0    5000.0        21           27   \n",
       "1  3.47    2.68          9.0        111.0    5000.0        21           27   \n",
       "2  2.68    3.47          9.0        154.0    5000.0        19           26   \n",
       "3  3.19    3.40         10.0        102.0    5500.0        24           30   \n",
       "4  3.19    3.40          8.0        115.0    5500.0        18           22   \n",
       "\n",
       "   price  \n",
       "0  13495  \n",
       "1  16500  \n",
       "2  16500  \n",
       "3  13950  \n",
       "4  17450  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code\n",
    "# Assuming 'fuel_type' is the first column (index 0)\n",
    "dict_replace = {'gas': 0, 'diesel': 1}\n",
    "df2.iloc[:, 0] = df2.iloc[:, 0].replace(dict_replace)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3851124",
   "metadata": {},
   "source": [
    "## 2.2 : Define your X and y: your dependent variable is fuel_type, the rest of the variables are your independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3735085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "X = df2.iloc[:, df2.columns != 'fuel_type']  # Independent variables (excluding fuel_type)\n",
    "y = df2['fuel_type']  # Dependent variable (fuel_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86f4df",
   "metadata": {},
   "source": [
    "## 2.3 Split your data into training and testing set. Use test_size=0.3, random_state=746 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e6c1b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_new shape: (136, 14)\n",
      "X_test_new shape: (59, 14)\n",
      "y_train_new shape: (136,)\n",
      "y_test_new shape: (59,)\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, y, test_size=0.3, random_state=746)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"X_train_new shape:\", X_train_new.shape)\n",
    "print(\"X_test_new shape:\", X_test_new.shape)\n",
    "print(\"y_train_new shape:\", y_train_new.shape)\n",
    "print(\"y_test_new shape:\", y_test_new.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2fd64",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea935a",
   "metadata": {},
   "source": [
    "### 3.1 Use Logistic regression to classify your data. Print/report your confusion matrix, classification report and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab66e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[50  0]\n",
      " [ 0  9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        59\n",
      "   macro avg       1.00      1.00      1.00        59\n",
      "weighted avg       1.00      1.00      1.00        59\n",
      "\n",
      "\n",
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have already split your data into X_train_new, X_test_new, y_train_new, y_test_new\n",
    "\n",
    "# Label encoding for the target variable if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_new)\n",
    "y_test_encoded = label_encoder.transform(y_test_new)\n",
    "\n",
    "# Creating a pipeline for Logistic Regression\n",
    "numeric_features = X_train_new.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "# Logistic Regression model within a pipeline\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Fitting the pipeline\n",
    "logreg_pipeline.fit(X_train_new, y_train_encoded)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg_pipeline.predict(X_test_new)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_encoded, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Calculating AUC\n",
    "auc = roc_auc_score(y_test_encoded, y_pred)\n",
    "print(\"\\nAUC Score:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3360f1",
   "metadata": {},
   "source": [
    "### 3.2 Use Naive Bayes to classify your data. Print/report your confusion matrix, classification report and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "131bcdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[50  0]\n",
      " [ 0  9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        59\n",
      "   macro avg       1.00      1.00      1.00        59\n",
      "weighted avg       1.00      1.00      1.00        59\n",
      "\n",
      "\n",
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Label encoding for the target variable if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_new)\n",
    "y_test_encoded = label_encoder.transform(y_test_new)\n",
    "\n",
    "# Creating a pipeline for Naive Bayes\n",
    "numeric_features = X_train_new.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "# Naive Bayes model within a pipeline\n",
    "naive_bayes_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline\n",
    "naive_bayes_pipeline.fit(X_train_new, y_train_encoded)\n",
    "\n",
    "# Predictions\n",
    "y_pred = naive_bayes_pipeline.predict(X_test_new)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_encoded, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Calculating AUC\n",
    "auc = roc_auc_score(y_test_encoded, y_pred)\n",
    "print(\"\\nAUC Score:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495f2d4",
   "metadata": {},
   "source": [
    "### 3.3 Use KNN to classify your data. First find the optimal k and than run you classification. Print/report your confusion matrix, classification report and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afd53354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value: 1\n",
      "Confusion Matrix:\n",
      "[[50  0]\n",
      " [ 0  9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        59\n",
      "   macro avg       1.00      1.00      1.00        59\n",
      "weighted avg       1.00      1.00      1.00        59\n",
      "\n",
      "\n",
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Label encoding for the target variable if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_new)\n",
    "y_test_encoded = label_encoder.transform(y_test_new)\n",
    "\n",
    "# Creating a pipeline for KNN\n",
    "numeric_features = X_train_new.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "# KNN model within a pipeline\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'classifier__n_neighbors': range(1, 21)}  # Trying K values from 1 to 20\n",
    "\n",
    "# Perform GridSearchCV to find the best K\n",
    "grid_search = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_new, y_train_encoded)\n",
    "\n",
    "# Get the best K value\n",
    "best_k = grid_search.best_params_['classifier__n_neighbors']\n",
    "print(\"Best K value:\", best_k)\n",
    "\n",
    "# Use the best K to classify the data\n",
    "best_knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=best_k))\n",
    "])\n",
    "\n",
    "best_knn_pipeline.fit(X_train_new, y_train_encoded)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_knn_pipeline.predict(X_test_new)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_encoded, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Calculating AUC\n",
    "auc = roc_auc_score(y_test_encoded, y_pred)\n",
    "print(\"\\nAUC Score:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3371eae",
   "metadata": {},
   "source": [
    "### 3.4 Choose one: SVM or Random Forest to classify your data. Print/report your confusion matrix, classification report and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7b82419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[50  0]\n",
      " [ 1  8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        50\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.98        59\n",
      "   macro avg       0.99      0.94      0.97        59\n",
      "weighted avg       0.98      0.98      0.98        59\n",
      "\n",
      "\n",
      "AUC Score: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Label encoding for the target variable if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_new)\n",
    "y_test_encoded = label_encoder.transform(y_test_new)\n",
    "\n",
    "# Creating a pipeline for Random Forest\n",
    "numeric_features = X_train_new.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "# Random Forest model within a pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Adjust parameters as needed\n",
    "])\n",
    "\n",
    "# Fitting the pipeline\n",
    "rf_pipeline.fit(X_train_new, y_train_encoded)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_pipeline.predict(X_test_new)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_encoded, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Calculating AUC\n",
    "auc = roc_auc_score(y_test_encoded, y_pred)\n",
    "print(\"\\nAUC Score:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c75879",
   "metadata": {},
   "source": [
    "### 3.5 Compare your results and comment on your findings. Which one(s) did the best job? What could have been the problem with the ones that did not work? etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089aef3",
   "metadata": {},
   "source": [
    "#your answer\n",
    "- **Logistic Regression (3.1):**\n",
    "  - **Pros:** Achieved perfect scores across all metrics (precision, recall, f1-score) and an AUC of 1.0, indicating flawless performance.\n",
    "  - **Cons:** No apparent issues observed based on the provided output.\n",
    "\n",
    "- **Naive Bayes (3.2):**\n",
    "  - **Pros:** Also demonstrated perfect scores across all metrics and an AUC of 1.0, signifying excellent performance.\n",
    "  - **Cons:** No apparent issues based on the provided output.\n",
    "\n",
    "- **KNN (3.3):**\n",
    "  - **Pros:** Achieved perfect scores across all metrics and an AUC of 1.0, indicating outstanding performance.\n",
    "  - **Cons:** No apparent issues based on the provided output.\n",
    "\n",
    "- **Random Forest (3.4):**\n",
    "  - **Pros:** High accuracy and strong precision for both classes. However, a slight drop in recall for class 1 resulted in a single misclassification.\n",
    "  - **Cons:** Slightly lower recall for class 1 compared to other models.\n",
    "\n",
    "### Comparison and Observations:\n",
    "- **Top Performers:** Logistic Regression, Naive Bayes, and KNN all displayed flawless performance, achieving perfect scores across metrics and AUC of 1.0.\n",
    "- **Minor Variance:** Random Forest, while highly accurate, exhibited a slight decrease in recall for class 1, leading to a single misclassification.\n",
    "- **Insights:** Logistic Regression, Naive Bayes, and KNN performed equally well, exhibiting optimal accuracy without any misclassifications. In contrast, Random Forest experienced a minor challenge in precisely identifying instances from class 1, resulting in a single misclassification.\n",
    "\n",
    "### Analysis:\n",
    "- **Strengths:** Logistic Regression, Naive Bayes, and KNN demonstrated robustness and accuracy without misclassifications.\n",
    "- **Potential Weakness:** Random Forest showed a minor issue in correctly identifying instances from class 1, leading to a single misclassification.\n",
    "\n",
    "In conclusion, all models exhibited impressive performance. Logistic Regression, Naive Bayes, and KNN achieved flawless accuracy. However, Random Forest, while highly accurate overall, encountered a slight challenge in accurately identifying instances from class 1. Overall, each model displayed strong predictive capabilities, with slight variations in performance on this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3740e1a",
   "metadata": {},
   "source": [
    "## 4. Bonus question (5 extra points)\n",
    "**Try to fix the inbalanced nature of the data with a tool from the lecture. Run one of the classification methods (preferable one that \"failed\" before) and see if you get better results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fdf64977",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Apply SMOTE only to the training set to avoid data leakage\u001b[39;00m\n\u001b[1;32m      5\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train_new, y_train_new)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize and fit the Random Forest classifier\u001b[39;00m\n\u001b[1;32m      9\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/imblearn/base.py:104\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    105\u001b[0m     arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m    106\u001b[0m     X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.11/site-packages/sklearn/utils/multiclass.py:216\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    208\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m ]:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "#your code\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Apply SMOTE only to the training set to avoid data leakage\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_new, y_train_new)\n",
    "\n",
    "# Initialize and fit the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_test = rf_classifier.predict(X_test_new)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(y_test_new, y_pred_test)\n",
    "print(\"Confusion Matrix (Test Set):\")\n",
    "print(confusion_matrix_test)\n",
    "\n",
    "# Classification report\n",
    "classification_report_test = classification_report(y_test_new, y_pred_test)\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report_test)\n",
    "\n",
    "# Calculating AUC\n",
    "auc_score_test = roc_auc_score(y_test_new, y_pred_test)\n",
    "print(\"\\nAUC Score (Test Set):\", auc_score_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482702d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
